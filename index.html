<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Line Insertion Tutorial</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      padding: 30px;
      text-align: center;
      margin: 0;
      background-color: #f9f9f9;
    }

    /* Main tutorial box */
    #stepBox {
      padding: 20px;
      border: 2px solid #000;
      border-radius: 10px;
      display: inline-block;
      font-size: 1.2em;
      min-height: 100px;
      width: 60%;
      background-color: #fff;
      margin-top: 100px;
    }

    /* Status message */
    #status {
      margin-top: 20px;
      font-size: 0.9em;
      color: green;
    }

    /* Command log container below the step box */
    #logContainer {
      margin: 40px auto 0 auto;
      width: 70%;
      background: #fff;
      border: 2px solid #ccc;
      border-radius: 10px;
      overflow-y: auto;
      max-height: 200px;
      text-align: left;
      padding: 10px;
      box-shadow: 0 0 10px rgba(0,0,0,0.05);
    }

    #logContainer h3 {
      margin-top: 0;
    }

    .log-entry {
      font-size: 0.9em;
      border-bottom: 1px solid #eee;
      padding: 4px 0;
    }

    /* Live transcript at the bottom of the screen */
    #liveTranscript {
      position: fixed;
      bottom: 20px;
      left: 50%;
      transform: translateX(-50%);
      background: #222;
      color: #0f0;
      padding: 10px 20px;
      border-radius: 10px;
      font-size: 1em;
      font-family: monospace;
      opacity: 0.9;
      z-index: 999;
    }
  </style>
</head>
<body>

  <!-- Page heading -->
  <h1>Line Insertion Tutorial</h1>

  <!-- Tutorial step box -->
  <div id="stepBox">Say "next" to begin...</div>

  <!-- Status (changes on voice feedback and actions) -->
  <div id="status">Status: Listening...</div>

  <!-- Log appears under the main box -->
  <div id="logContainer">
    <h3>Command Log</h3>
    <div id="log"></div>
  </div>

  <!-- Floating transcript of most recent command -->
  <div id="liveTranscript">ðŸŽ¤ Waiting for input...</div>

  <script>
    const steps = [
      "Step 1: Start with an empty list.",
      "Step 2: Insert the first line of code at position 0.",
      "Step 3: Move the cursor to the next position.",
      "Step 4: Insert the second line at position 1.",
      "Step 5: Repeat until all lines are inserted.",
      "Step 6: Finalize and save the document."
    ];

    let currentStep = 0;

    // Display current step
    function updateStep() {
      document.getElementById("stepBox").innerText = steps[currentStep];
      if (currentStep === steps.length - 1) {
        document.getElementById("status").innerText = "âœ… You are on the final step!";
      } else {
        document.getElementById("status").innerText = `Step ${currentStep + 1} of ${steps.length}`;
      }
    }

    // Add command to log list
    function logCommand(text) {
      const log = document.getElementById("log");
      const entry = document.createElement("div");
      entry.className = "log-entry";
      entry.textContent = `ðŸŽ¤ ${new Date().toLocaleTimeString()}: ${text}`;
      log.appendChild(entry);
      log.scrollTop = log.scrollHeight; // auto-scroll to bottom
    }

    updateStep(); // show first step on load

    // Set up Web Speech API
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    if (!SpeechRecognition) {
      alert("Your browser doesn't support speech recognition.");
    } else {
      const recognition = new SpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = false;
      recognition.lang = "en-US";

      recognition.onresult = (event) => {
        const raw = event.results[event.results.length - 1][0].transcript.trim().toLowerCase();
        const cleaned = raw.replace(/[^\w\s]/gi, "").trim(); // remove punctuation

        // Show and log what was heard
        document.getElementById("liveTranscript").innerText = `ðŸŽ¤ ${raw}`;
        logCommand(raw);

        // Voice command handling
        if (/\bnext\b/.test(cleaned)) {
          if (currentStep < steps.length - 1) {
            currentStep++;
            updateStep();
          } else {
            document.getElementById("status").innerText = "ðŸš« You're already at the final step.";
          }
        } else if (/\b(previous|back|go back)\b/.test(cleaned)) {
          if (currentStep > 0) {
            currentStep--;
            updateStep();
          } else {
            document.getElementById("status").innerText = "ðŸš« You're already at the first step.";
          }
        } else if (/\brestart\b/.test(cleaned)) {
          currentStep = 0;
          updateStep();
          document.getElementById("status").innerText = "ðŸ”„ Restarted the tutorial.";
        }
      };

      // Show error and restart listener
      recognition.onerror = (event) => {
        document.getElementById("status").innerText = `âš ï¸ Error: ${event.error}`;
        document.getElementById("liveTranscript").innerText = `âš ï¸ Error: ${event.error}`;
        logCommand(`ERROR: ${event.error}`);
      };

      // Restart listener when it ends unexpectedly
      recognition.onend = () => {
        document.getElementById("status").innerText = "ðŸ”„ Restarting voice listener...";
        setTimeout(() => recognition.start(), 500);
      };

      // Start voice recognition
      recognition.start();
    }
  </script>

</body>
</html>